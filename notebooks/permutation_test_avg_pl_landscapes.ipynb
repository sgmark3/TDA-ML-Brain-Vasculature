{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages from ripser and persim (scikit-tda packages) for computing \n",
    "## average persistence landscapes\n",
    "\n",
    "from ripser import ripser\n",
    "from persim.landscapes import (\n",
    "PersLandscapeApprox,\n",
    "average_approx,\n",
    "snap_pl,\n",
    "plot_landscape,\n",
    "plot_landscape_simple\n",
    ")\n",
    "import gudhi.representations\n",
    "import gudhi as gd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import math\n",
    "from ediblepickle import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from persim.persistent_entropy import *\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the filenames and locations to load the persistence diagram datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_in_str = '../data/annotated_PH_2020_500/'\n",
    "\n",
    "directory = os.fsencode(directory_in_str)\n",
    "folders=[]\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    foldername = os.fsdecode(folder)\n",
    "    if foldername.startswith('PH_640_'):\n",
    "        folders.append(foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get persistence data stored in files within the folder whose location is passed through the keyword argument path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_edges_threshold = 0\n",
    "\n",
    "\"\"\"\n",
    "Returns persistence data\n",
    "Inputs -- path: local_path\n",
    "       -- starts_with: the string that the filenames start with if needed\n",
    "       -- ends_with: the string that the filenames end with if needed\n",
    "       -- threshold: number of edges threshold of the underlying vascular networks\n",
    "\"\"\"\n",
    "\n",
    "def get_data(path=None,starts_with=None,ends_with=None,threshold=None):\n",
    "    files = [os.fsdecode(file) for file in os.listdir(path)]\n",
    "    persistence_data={}\n",
    "    for filename in files:\n",
    "        if starts_with and ends_with:\n",
    "            if filename.startswith(starts_with) and filename.endswith(ends_with):\n",
    "                data = []\n",
    "                with open(path+filename) as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    for row in reader:\n",
    "                        data.append([float(x) for x in row])\n",
    "                if threshold == 0:\n",
    "                    persistence_data[filename]=[item for item in data[1:] if item[1]!=np.inf]\n",
    "                else:\n",
    "                    if data[0][1] >= threshold:\n",
    "                        persistence_data[filename]=[item for item in data[1:] if item[1]!=np.inf]\n",
    "        elif starts_with:\n",
    "            if filename.startswith(starts_with):\n",
    "                data = []\n",
    "                with open(path+filename) as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    for row in reader:\n",
    "                        data.append([float(x) for x in row])\n",
    "                if threshold == 0:\n",
    "                    persistence_data[filename]=[item for item in data[1:] if item[1]!=np.inf]\n",
    "                else:\n",
    "                    if data[0][1] >= threshold:\n",
    "                        persistence_data[filename]=[item for item in data[1:] if item[1]!=np.inf]\n",
    "        elif ends_with:\n",
    "            if filename.endswith(ends_with):\n",
    "                data = []\n",
    "                with open(path+filename) as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    for row in reader:\n",
    "                        data.append([float(x) for x in row])\n",
    "                if threshold == 0:\n",
    "                    persistence_data[filename]=[item for item in data[1:] if item[1]!=np.inf]\n",
    "                else:\n",
    "                    if data[0][1] >= threshold:\n",
    "                        persistence_data[filename]=[item for item in data[1:] if item[1]!=np.inf]\n",
    "                \n",
    "    return persistence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_PHs={}\n",
    "for folder in folders:\n",
    "    og_PHs[folder] = get_data('../data/annotated_PH_2020_500/'+folder+'/',starts_with=('ph_'),threshold=number_of_edges_threshold)\n",
    "\n",
    "shuffled_PHs={}\n",
    "for folder in folders:\n",
    "    shuffled_PHs[folder] = get_data('../data/annotated_PH_2020_500/'+folder+'/',starts_with=('shuffled_ph_'),threshold=number_of_edges_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following helper function to compute average of approximate persistence landscapes from the persistence diagram data, which is stored within a dictionary of dictinoaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_pl(persistence_data):\n",
    "    pl_data = []\n",
    "    for key,value in persistence_data.items():\n",
    "        if value:\n",
    "            for subkey,subvalue in value.items():\n",
    "                pl_data.append(PersLandscapeApprox(dgms=[np.array([[item[0],item[1]] for item in subvalue])],\\\n",
    "                                                   hom_deg=0))\n",
    "    return average_approx(pl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute distance between a pair of persistence landscapes using norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm(pl1,pl2,norm=None):\n",
    "    [pl1_snapped, pl2_snapped] = snap_pl([pl1, pl2])\n",
    "    diff_pl = pl1_snapped - pl2_snapped\n",
    "    if norm == 'sup':\n",
    "        return diff_pl.sup_norm()\n",
    "    elif norm == 'l1':\n",
    "        return diff_pl.p_norm(1)\n",
    "    else:\n",
    "        return dff_pl.p_norm(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the following helper function to compute approximate persistence landscapes from the persistence diagram data, which is stored within a dictionary of dictinoaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approximate_pl(persistence_data):\n",
    "    pl_data = []\n",
    "    for key,value in persistence_data.items():\n",
    "        if value:\n",
    "            for subkey,subvalue in value.items():\n",
    "                pl_data.append(PersLandscapeApprox(dgms=[np.array([[item[0],item[1]] for item in subvalue])],\\\n",
    "                                                   hom_deg=0))\n",
    "    return pl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation test:\n",
    "Refer to the following link for another example: https://persim.scikit-tda.org/en/latest/notebooks/Differentiation%20with%20Persistence%20Landscapes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10118723629465924\n",
      "0.016072358355857463\n",
      "0.01888657275803584\n",
      "0.011823338950517681\n",
      "0.0075804865898486395\n",
      "0.00960125550896114\n",
      "0.0061699603908349915\n",
      "0.005201690881080592\n",
      "0.004034773803596806\n",
      "0.010179120239791319\n",
      "0.009394765134095304\n",
      "0.012768985527570997\n",
      "0.022765238109996727\n",
      "0.004790025324519739\n",
      "0.006596851210469962\n",
      "0.019367296264292885\n",
      "0.011952375920400375\n",
      "0.007083639487198548\n",
      "0.005979880579895097\n",
      "0.0100478982986642\n",
      "0.013954316916238108\n",
      "0.008945763547656832\n",
      "0.008525394830944333\n",
      "0.012825598171914442\n",
      "0.006427398355047201\n",
      "0.010107095237787758\n",
      "0.006653191562382282\n",
      "0.010484665767278259\n",
      "0.015739436952981738\n",
      "0.008065674963981431\n",
      "0.010490382724245885\n",
      "0.012399757442288675\n",
      "0.00587418638559037\n",
      "0.007838534822981691\n",
      "0.028395745518597228\n",
      "0.010227228019223975\n",
      "0.010811146698822237\n",
      "0.014262141874806303\n",
      "0.005223416739041843\n",
      "0.012936145243961208\n",
      "0.010835436698976287\n",
      "0.006785129365749293\n",
      "0.011502920160712554\n",
      "0.01987717953634624\n",
      "0.010278950208927731\n",
      "0.010125290329591474\n",
      "0.012720056790550813\n",
      "0.011464631238519221\n",
      "0.0054067212810578365\n",
      "0.004819677933449153\n",
      "0.009541856484794657\n",
      "0.006209984792944306\n",
      "0.008830433878385863\n",
      "0.01092831231405511\n",
      "0.0065709579764947346\n",
      "0.005562607011005166\n",
      "0.010937538996781224\n",
      "0.008591625490795424\n",
      "0.016991842341080907\n",
      "0.010794773201611187\n",
      "0.010617406980944398\n",
      "0.005982851866859817\n",
      "0.011666444514131485\n",
      "0.009677006910133998\n",
      "0.005288761765431527\n",
      "0.013677275731867597\n",
      "0.007079694273220041\n",
      "0.007681170327351335\n",
      "0.008155478608648153\n",
      "0.011412062831542627\n",
      "0.006560407655277489\n",
      "0.012779786734433772\n",
      "0.007250981994898403\n",
      "0.009715801043925922\n",
      "0.015766364459209578\n",
      "0.014402893905780256\n",
      "0.00935446285753986\n",
      "0.00890882733882582\n",
      "0.005727521455015608\n",
      "0.011565364887952949\n",
      "0.006598854227998635\n",
      "0.0074399344919969385\n",
      "0.0067131784122118066\n",
      "0.011295093713191331\n",
      "0.0052042852957076315\n",
      "0.01379140773779429\n",
      "0.012405539805371353\n",
      "0.0116313526464367\n",
      "0.0062079746983915995\n",
      "0.008855606862116325\n",
      "0.01155696028394624\n",
      "0.0057943369361016794\n",
      "0.010053891557832678\n",
      "0.014285005569585084\n",
      "0.012368407510190575\n",
      "0.015605329086337202\n",
      "0.009027919599938039\n",
      "0.005020297197395434\n",
      "0.009036624921599581\n",
      "0.011028911218905708\n",
      "0.006498943065062865\n",
      "There were 0 shuffles out of 100 that were more significant than the true labelling. Thus, the p-value is 0.0.\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "comb_pl = get_approximate_pl(og_PHs) + get_approximate_pl(shuffled_PHs)\n",
    "significance = get_norm(get_average_pl(og_PHs),get_average_pl(shuffled_PHs),norm='sup')\n",
    "print(significance)\n",
    "n=len(comb_pl)\n",
    "sig_count = 0\n",
    "num_perms=100\n",
    "sigs=[]\n",
    "\n",
    "for shuffle in range(num_perms):\n",
    "    A_indices = random.choice(range(n),n//2)\n",
    "    B_indices = [_ for _ in range(n) if _ not in A_indices]\n",
    "\n",
    "    A_pl = [comb_pl[i] for i in A_indices]\n",
    "    B_pl = [comb_pl[j] for j in B_indices]\n",
    "\n",
    "    A_avg = average_approx(A_pl)\n",
    "    B_avg = average_approx(B_pl)\n",
    "    [A_avg_sn, B_avg_sn] = snap_pl([A_avg,B_avg])\n",
    "\n",
    "    AB_diff = A_avg_sn - B_avg_sn\n",
    "    sig = AB_diff.sup_norm()\n",
    "    if (sig >= significance): sig_count += 1\n",
    "    sigs.append(sig)\n",
    "    print(sig)\n",
    "\n",
    "pval = sig_count/num_perms\n",
    "\n",
    "print(f'There were {sig_count} shuffles out of {num_perms} that',\n",
    "     'were more significant than the true labelling. Thus, the',\n",
    "     f'p-value is {pval}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
